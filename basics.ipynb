{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pragalvhasharma/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/nemoguardrails/rails/llm/config.py:527: RuntimeWarning: fields may not start with an underscore, ignoring \"_type\"\n",
      "  class RailsConfig(BaseModel):\n",
      "/Users/pragalvhasharma/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/nemoguardrails/rails/llm/config.py:527: RuntimeWarning: fields may not start with an underscore, ignoring \"_source\"\n",
      "  class RailsConfig(BaseModel):\n"
     ]
    }
   ],
   "source": [
    "colang_content = \"\"\"\n",
    "define user express greeting\n",
    "  \"hello\"\n",
    "  \"hi\"\n",
    "\n",
    "define bot express greeting\n",
    "  \"Hello there!! Can I help you today?\"\n",
    "\n",
    "define flow hello\n",
    "  user express greeting\n",
    "  bot express greeting\n",
    "\"\"\"\n",
    "yaml_content = \"\"\"\n",
    "models:\n",
    "- type: main\n",
    "  engine: openai\n",
    "  model: gpt-3.5-turbo-1106\n",
    "# - type: embeddings\n",
    "#   engine: openai\n",
    "#   model: text-embedding-ada-002\n",
    "\"\"\"\n",
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'OpenAI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rails \u001b[38;5;241m=\u001b[39m \u001b[43mLLMRails\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/nemoguardrails/rails/llm/llmrails.py:204\u001b[0m, in \u001b[0;36mLLMRails.__init__\u001b[0;34m(self, config, llm, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_config()\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM engines (main engine and action engines if specified).\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_llms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM Generate actions and register them.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m llm_generation_actions_class \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    208\u001b[0m     LLMGenerationActions\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcolang_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m LLMGenerationActionsV2dotx\n\u001b[1;32m    211\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/nemoguardrails/rails/llm/llmrails.py:355\u001b[0m, in \u001b[0;36mLLMRails._init_llms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m         log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    351\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support streaming.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm_config\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m \u001b[43mprovider_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mregister_action_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/pydantic/main.py:1100\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Downloads/Prag GO to Documents/Comp Sci/MY Projects/NEMO Guardrails DEMO/env/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:366\u001b[0m, in \u001b[0;36mChatOpenAI.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    350\u001b[0m client_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[1;32m    352\u001b[0m         values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    363\u001b[0m }\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 366\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params)\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_client\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    368\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mAsyncOpenAI(\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params\n\u001b[1;32m    370\u001b[0m     )\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'OpenAI'"
     ]
    }
   ],
   "source": [
    "rails = LLMRails(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m rails\u001b[38;5;241m.\u001b[39mgenerate_async(prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rails' is not defined"
     ]
    }
   ],
   "source": [
    "res = await rails.generate_async(prompt=\"Hello\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of just passing a prompt, we can also pass a complete conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"}\n",
    "]\n",
    "res = await rails.generate_async(messages=messages)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use variables in combination with if/else statements to make the behavior more dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello there!! Can I help you today?\"\n",
    "\n",
    "define bot personal greeting\n",
    "    \"Hello $username, nice to see you again!\"\n",
    "\n",
    "define flow hello\n",
    "    user express greeting\n",
    "    if $username\n",
    "        bot personal greeting\n",
    "    else\n",
    "        bot express greeting\n",
    "\"\"\"\n",
    "\n",
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")\n",
    "rails = LLMRails(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"}\n",
    "]\n",
    "res = await rails.generate_async(messages=messages)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"username\": \"Markus\"}},\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"},\n",
    "]\n",
    "res = await rails.generate_async(messages=messages)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with LangChain\n",
    "\n",
    "We don´t want to substitute the probabistic bevahiour with a deterministic behaviour - we want to combine it. \n",
    "We can use `Actions` to integrate LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello there!! Can I help you today?\"\n",
    "\n",
    "define bot personal greeting\n",
    "    \"Hello $username, nice to see you again!\"\n",
    "\n",
    "define flow hello\n",
    "    user express greeting\n",
    "    if $username\n",
    "      bot personal greeting\n",
    "    else\n",
    "        bot express greeting\n",
    "\n",
    "define flow\n",
    "    user ...\n",
    "    $answer = execute qa_chain(query=$last_user_message)\n",
    "    bot $answer\n",
    "\"\"\"\n",
    "\n",
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")\n",
    "rails = LLMRails(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "vectorstore = Chroma.from_texts([\"CatBank's Furry Paws Credit Card offers 2% cashback on pet stores and 1% on all other purchases.\",\n",
    "                                 \"Meow Loans at CatBank come with a competitive 5% APR, subject to your catnip credit score.\",\n",
    "                                 \"Earn up to 4% interest with CatBank's Kitty Savers account, with a minimum deposit of $500.\",\n",
    "                                 \"Invest in the Whisker Growth Fund with a minimum of $1,000 and enjoy purr-tential annual returns of 7%.\",\n",
    "                                 \"Open a Feline Secure savings account with just $100; enjoy up to 3% interest with no monthly fees.\"],\n",
    "                                embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt_template = \"\"\"You are a helpful bot for our Bank. Only answer if your have got content in \"Context\".\n",
    "Otherwise tell the user in a friendly way that you do not know and can not help with that.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer here:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=rails.llm, # Use llm attached to rail instance\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.register_action(qa, name=\"qa_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [{\"role\": \"user\",\"content\": \"Whats the minimum deposit for CatBank's Kitty Savers account?\"}]\n",
    "bot_message = await rails.generate_async(messages=history)\n",
    "print(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [{\"role\": \"user\",\"content\": \"Make a joke about a cow\"}]\n",
    "bot_message = await rails.generate_async(messages=history)\n",
    "print(bot_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normally don´t want to our bot to answer to questions not related to our business topics, so we add Guardrails which cover specific off topic questions and also a chit-chat category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colang_content = \"\"\"\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello there!! Can I help you with your cat-related banking today?\"\n",
    "\n",
    "define bot personal greeting\n",
    "    \"Hello $username, nice to see you again! Hope your cat's doing well!\"\n",
    "\n",
    "define flow hello\n",
    "    user express greeting\n",
    "    if $username\n",
    "        bot personal greeting\n",
    "    else\n",
    "        bot express greeting\n",
    "\n",
    "define user ask about dogs\n",
    "    \"Can I get a loan for my dog?\"\n",
    "    \"Do you provide pet insurance for dogs?\"\n",
    "    \"What about doggie credit cards?\"\n",
    "\n",
    "define bot no dogs policy\n",
    "    \"Here at CatBank, we're all about cats! We don't offer services for dogs, but we can help with any cat-related banking needs.\"\n",
    "\n",
    "define flow dog policy\n",
    "    user ask about dogs\n",
    "    bot no dogs policy\n",
    "\n",
    "define user silly cat question\n",
    "    \"Can my cat open its own bank account?\"\n",
    "    \"Do you think cats are better bankers than humans?\"\n",
    "    \"Can I use a picture of my cat as my credit card design?\"\n",
    "\n",
    "define bot respond to silly cat question\n",
    "    \"While we love your cat's enthusiasm, only humans can open bank accounts. But we totally agree that cats would make amazing bankers, and yes, your credit card can definitely feature your cat's majestic portrait!\"\n",
    "\n",
    "define flow silly cat questions\n",
    "    user silly cat question\n",
    "    bot respond to silly cat question\n",
    "\n",
    "define user chit chat\n",
    "    \"What do you think about the latest movie?\"\n",
    "    \"Got any weekend plans?\"\n",
    "    \"Can you tell me a joke?\"\n",
    "\n",
    "define bot finance only\n",
    "    \"Sorry, I do cat related finance advice only!\"\n",
    "\n",
    "define flow chit chat\n",
    "    user chit chat\n",
    "    bot finance only\n",
    "\n",
    "define flow\n",
    "    user ...\n",
    "    $answer = execute qa_chain(query=$last_user_message)\n",
    "    bot $answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=new_colang_content\n",
    ")\n",
    "rails = LLMRails(config=config)\n",
    "rails.register_action(qa, name=\"qa_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"username\": \"Markus\"}},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "]\n",
    "res = await rails.generate_async(messages=messages)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\",\"content\": \"Can you tell me a joke?\"}]\n",
    "bot_message = await rails.generate_async(messages=messages)\n",
    "print(bot_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do execute arbitrary functions or use functions, which make a follow up request to an LLM. Here is an example with Doctran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import DoctranPropertyExtractor\n",
    "from typing import Sequence, Any\n",
    "from langchain.schema import Document\n",
    "\n",
    "class CustomDoctranPropertyExtractor(DoctranPropertyExtractor):\n",
    "    def transform_documents(\n",
    "            self, documents: Sequence[Document], **kwargs: Any\n",
    "    ) -> Sequence[Document]:\n",
    "\n",
    "        \"\"\"Async method is currently broken (Document cant be used in async).\"\"\"\n",
    "        try:\n",
    "            from doctran import Doctran, ExtractProperty\n",
    "\n",
    "            doctran = Doctran(\n",
    "                openai_api_key=self.openai_api_key, openai_model=self.openai_api_model\n",
    "            )\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Install doctran to use this parser. (pip install doctran)\"\n",
    "            )\n",
    "\n",
    "        properties = [ExtractProperty(**property) for property in self.properties]\n",
    "        for d in documents:\n",
    "            doctran_doc = doctran.parse(content=d.page_content)\n",
    "            extracted_properties = doctran_doc.extract(\n",
    "                properties=properties).execute()\n",
    "\n",
    "            d.metadata[\"extracted_properties\"] = extracted_properties\n",
    "        return documents\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "async def get_bank_branch_address(branch):\n",
    "    properties = [\n",
    "        {\n",
    "            \"name\": \"mentioned_branch\",\n",
    "            \"description\": \"The bank branch mentioned in this query.\",\n",
    "            \"type\": \"string\",\n",
    "            \"required\": True\n",
    "        }\n",
    "    ]\n",
    "    property_extractor = CustomDoctranPropertyExtractor(\n",
    "        properties=properties, openai_api_model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    documents = [Document(page_content=branch)]\n",
    "    extracted_documents = property_extractor.transform_documents(\n",
    "        documents=documents\n",
    "    )\n",
    "    print(\"EXTRACTED_DOCS: \", extracted_documents)\n",
    "    branch_name = extracted_documents[0].metadata['extracted_properties'].transformed_content\n",
    "\n",
    "    branch_addresses = {\n",
    "        \"Central CatBank\": \"123 Feline Street, Cat City\",\n",
    "        \"CatBank North\": \"456 Purr Avenue, Kitty Corner\",\n",
    "        \"CatBank South\": \"789 Whisker Way, Tabby Town\",\n",
    "        \"Downtown CatBank\": \"101 Claw Circle, Meow Metro\"\n",
    "    }\n",
    "\n",
    "    address = branch_addresses.get(branch_name)\n",
    "    if address:\n",
    "        return f\"The address for {branch_name} is {address}.\"\n",
    "    else:\n",
    "        return \"Branch not found.\"\n",
    "\n",
    "\n",
    "\n",
    "function_colang_content = \"\"\"\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello there!! Can I help you with your cat-related banking today?\"\n",
    "\n",
    "define bot personal greeting\n",
    "    \"Hello $username, nice to see you again! Hope your cat's doing well!\"\n",
    "\n",
    "define flow hello\n",
    "    user express greeting\n",
    "    if $username\n",
    "        bot personal greeting\n",
    "    else\n",
    "        bot express greeting\n",
    "\n",
    "define user ask about dogs\n",
    "    \"Can I get a loan for my dog?\"\n",
    "    \"Do you provide pet insurance for dogs?\"\n",
    "    \"What about doggie credit cards?\"\n",
    "\n",
    "define bot no dogs policy\n",
    "    \"Here at CatBank, we're all about cats! We don't offer services for dogs, but we can help with any cat-related banking needs.\"\n",
    "\n",
    "define flow dog policy\n",
    "    user ask about dogs\n",
    "    bot no dogs policy\n",
    "\n",
    "define user silly cat question\n",
    "    \"Can my cat open its own bank account?\"\n",
    "    \"Do you think cats are better bankers than humans?\"\n",
    "    \"Can I use a picture of my cat as my credit card design?\"\n",
    "\n",
    "define bot respond to silly cat question\n",
    "    \"While we love your cat's enthusiasm, only humans can open bank accounts. But we totally agree that cats would make amazing bankers, and yes, your credit card can definitely feature your cat's majestic portrait!\"\n",
    "\n",
    "define flow silly cat questions\n",
    "    user silly cat question\n",
    "    bot respond to silly cat question\n",
    "\n",
    "define user chit chat\n",
    "    \"What do you think about the latest movie?\"\n",
    "    \"Got any weekend plans?\"\n",
    "    \"Can you tell me a joke?\"\n",
    "\n",
    "define bot finance only\n",
    "    \"Sorry, I do cat related finance advice only!\"\n",
    "\n",
    "define flow chit chat\n",
    "    user chit chat\n",
    "    bot finance only\n",
    "\n",
    "define user inquire branch address\n",
    "    \"Wo finde ich die Central CatBank?\"\n",
    "    \"Wo ist CatBank North?\"\n",
    "    \"Kannst du mir sagen, wo CatBank South ist?\"\n",
    "    \"Wo ist Downtown CatBank?\"\n",
    "\n",
    "define flow inquire branch address\n",
    "    user inquire branch address\n",
    "    $address = execute get_bank_branch_address(branch=$last_user_message)\n",
    "    bot $address\n",
    "\n",
    "define flow\n",
    "    user ...\n",
    "    $answer = execute qa_chain(query=$last_user_message)\n",
    "    bot $answer\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=function_colang_content\n",
    ")\n",
    "rails = LLMRails(config=config)\n",
    "rails.register_action(qa, name=\"qa_chain\")\n",
    "rails.register_action(get_bank_branch_address, name=\"get_bank_branch_address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\",\"content\": \"Wo ist die Central CatBank\"}]\n",
    "bot_message = await rails.generate_async(messages=messages)\n",
    "print(bot_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subflow_colang_content = \"\"\"\n",
    "define user express greeting\n",
    "  \"hello\"\n",
    "  \"hi\"\n",
    "\n",
    "define bot greeting_authenticated\n",
    "  \"Welcome back to CatBank, $username! How can we assist you and your cat today?\"\n",
    "\n",
    "define bot greeting_unauthenticated\n",
    "  \"Welcome to CatBank! Please log in or create an account to begin.\"\n",
    "\n",
    "define subflow greeting with auth\n",
    "  if $user_auth\n",
    "    bot greeting_authenticated\n",
    "  else\n",
    "    bot greeting_unauthenticated\n",
    "\n",
    "define flow hello\n",
    "  user express greeting\n",
    "  do greeting with auth\n",
    "\"\"\"\n",
    "\n",
    "config = RailsConfig.from_content(\n",
    "  \tyaml_content=yaml_content,\n",
    "    colang_content=subflow_colang_content\n",
    ")\n",
    "rails = LLMRails(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"user_auth\": False, \"username\": \"Markus\"}},\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"},\n",
    "]\n",
    "bot_message = await rails.generate_async(messages=messages)\n",
    "print(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"user_auth\": True, \"username\": \"Markus\"}},\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"},\n",
    "]\n",
    "bot_message = await rails.generate_async(messages=messages)\n",
    "print(bot_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
